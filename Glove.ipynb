{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains code for loading the GloVe vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabular object for storing words and its properties\n",
    "class Vocab(object):\n",
    "    def __init__(self):\n",
    "        self.PADDING = 0\n",
    "        self.UNKNOWN = 1\n",
    "        self.word2index = {'<pad>':0, '<unk>':1}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: '<pad>', 1: '<unk>'}\n",
    "        self.n_words = 2\n",
    "\n",
    "    # Save vocabulary properties to pickle for future reuse\n",
    "    def save_vocab(self):\n",
    "        with open('word2index.pickle', 'wb') as handle:\n",
    "            pickle.dump(self.word2index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('word2count.pickle', 'wb') as handle:\n",
    "            pickle.dump(self.word2count, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('index2word.pickle', 'wb') as handle:\n",
    "            pickle.dump(self.index2word, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(\"saved vocabs\")\n",
    "\n",
    "    # Load saved vocab properties\n",
    "    def load_vocab(self):\n",
    "        with open('word2index.pickle', 'rb') as handle:\n",
    "            self.word2index = pickle.load(handle)\n",
    "        with open('word2count.pickle', 'rb') as handle:\n",
    "            self.word2count = pickle.load(handle)\n",
    "        with open('index2word.pickle', 'rb') as handle:\n",
    "            self.index2word = pickle.load(handle)\n",
    "        self.n_words = len(self.word2index)\n",
    "    \n",
    "    \n",
    "    # add words in the sentence to Vocab         \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def word_to_id(self, word):\n",
    "        if not self.has_word(word):\n",
    "            return self.word2index['<unk>']\n",
    "        return self.word2index[word]\n",
    "\n",
    "    def load_word(self, word, count):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = count\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "            \n",
    "    def id_to_word(self, id_):\n",
    "        return self.index2word[id_]\n",
    "\n",
    "    def has_word(self, word):\n",
    "        return word in self.word2index\n",
    "\n",
    "    # add a word to vocab\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def get_length(self):\n",
    "        return self.n_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for loading pretrained GloVe into Vocab\n",
    "def load_glove(path, vocab, init_weight: np.array):\n",
    "    word_vectors = dict()\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            word, *values = line.split()\n",
    "            try:\n",
    "                if vocab.has_word(word):\n",
    "                    if word in word_vectors:\n",
    "                        # Let's use the first occurrence only.\n",
    "                        continue\n",
    "                    word_vector = np.array([float(v) for v in values])\n",
    "                    word_vectors[word] = word_vector\n",
    "            except ValueError:\n",
    "                # 840D GloVe file has some encoding errors...\n",
    "                # I think they can be ignored.\n",
    "                continue\n",
    "    glove_weight = np.zeros_like(init_weight)\n",
    "    # glove_weight[:] = word_vectors[vocab.unk_word]\n",
    "    for word in word_vectors:\n",
    "        word_index = vocab.word_to_id(word)\n",
    "        glove_weight[word_index, :] = word_vectors[word]\n",
    "    return glove_weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
