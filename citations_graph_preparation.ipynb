{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This contains the code for preprocessing the citation data. The preprocessed data will be used in node2vec algorithm to generate citation embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file is used to preprocess some data we will use later\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first get all sentences data and put them together\n",
    "citation_data_path_zipped = '/data/Dropbox/judge_embedding_data_sp18/citation.zip'\n",
    "processed_data_path = '/data/Dropbox/judge_embedding_data_sp18/processed_citations'\n",
    "citation_data_path = '../all_citations'\n",
    "processed_citation_path = '/data/Dropbox/judge_embedding_data_sp18/processed_citations/citation_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary_citation_data(data_folder_path,processed_data_folder_path,\n",
    "                                    data_binary_name=\"citation_data\", \n",
    "                                    data_count_limit = 999999999,verbose=1):\n",
    "    # data count limit is how many txt files do you want in total\n",
    "    # data dump limit is every how many txt files do you want to do a binary dump\n",
    "    start_time = time.time()\n",
    "    # for test purposes, data limit can be set to indicate how much data to use\n",
    "    data_count = 0\n",
    "    # give the circuit court main folder's path, read all data\n",
    "    folder_names = os.listdir(data_folder_path)\n",
    "    folder_names.sort()\n",
    "    #   judge_df = pandas.DataFrame(columns=[\"Judge_Name\",\"Year\",\"Sentence\"])\n",
    "    data_list = []\n",
    "    save_part_index = 0\n",
    "    \n",
    "    finished = False\n",
    "    \n",
    "    for folder_name in folder_names: # for each folder\n",
    "        if verbose > 0:\n",
    "            print(\"now process:\",folder_name,\"current data count:\",data_count,\"time used:\",time.time()-start_time)\n",
    "        \n",
    "        year = folder_name[-4:]\n",
    "        data_file_names = os.listdir(os.path.join(data_folder_path,folder_name))\n",
    "        \n",
    "\n",
    "        if finished:\n",
    "            break\n",
    "        \n",
    "        for file_name in data_file_names: # for each file\n",
    "            file_name_without_txt = file_name[:-4]\n",
    "            file_name_tokens = file_name_without_txt.split(\"_\")\n",
    "            \n",
    "            if len(file_name_tokens)<3:\n",
    "                print(\"file format incorrect at file:\",file_name)\n",
    "                continue\n",
    "            \n",
    "            caseid = file_name_tokens[1]\n",
    "            case_type =file_name_tokens[2]\n",
    "            judge_name = file_name_tokens[3] # we get the judge's name from the file name\n",
    "            \n",
    "            file_path = os.path.join(data_folder_path,folder_name,file_name)\n",
    "            fpt = open(file_path,\"r\")\n",
    "            \n",
    "            for line in fpt:\n",
    "                citation_name = line.strip()\n",
    "                new_data_entry = [caseid,year,judge_name,case_type,citation_name]\n",
    "                data_list.append(new_data_entry)\n",
    "                data_count += 1\n",
    "               \n",
    "            #sentence = fpt.read()\n",
    "            fpt.close()\n",
    "            \n",
    "            #new_data_entry = [caseid,year,judge_name,middle_part,sentence]\n",
    "            #data_list.append(new_data_entry)\n",
    "            #data_count += 1\n",
    "            \n",
    "            if data_count > data_count_limit: # for debugging purposes\n",
    "                finished = True\n",
    "                break\n",
    "    \n",
    "    df = pd.DataFrame(data_list,columns = [\"caseid\",\"year\",\"judge_last_name\",\"case_type\",\"citation_name\"])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now process: citation_1891 current data count: 0 time used: 0.006191253662109375\n",
      "now process: citation_1892 current data count: 0 time used: 0.03186917304992676\n",
      "now process: citation_1893 current data count: 5 time used: 0.37296319007873535\n",
      "now process: citation_1894 current data count: 11 time used: 0.6360573768615723\n",
      "now process: citation_1895 current data count: 32 time used: 0.7228295803070068\n",
      "now process: citation_1896 current data count: 39 time used: 0.8064494132995605\n",
      "now process: citation_1897 current data count: 63 time used: 0.8965437412261963\n",
      "now process: citation_1898 current data count: 109 time used: 1.0640411376953125\n",
      "now process: citation_1899 current data count: 133 time used: 1.154466152191162\n",
      "now process: citation_1900 current data count: 156 time used: 1.2659878730773926\n",
      "now process: citation_1901 current data count: 194 time used: 1.3966481685638428\n",
      "now process: citation_1902 current data count: 220 time used: 1.495680332183838\n",
      "now process: citation_1903 current data count: 258 time used: 1.6132209300994873\n",
      "now process: citation_1904 current data count: 311 time used: 1.8103251457214355\n",
      "now process: citation_1905 current data count: 341 time used: 1.9135386943817139\n",
      "now process: citation_1906 current data count: 384 time used: 2.0325570106506348\n",
      "now process: citation_1907 current data count: 453 time used: 2.153205394744873\n",
      "now process: citation_1908 current data count: 545 time used: 2.4037764072418213\n",
      "now process: citation_1909 current data count: 611 time used: 2.5058722496032715\n",
      "now process: citation_1910 current data count: 659 time used: 2.6559104919433594\n",
      "now process: citation_1911 current data count: 702 time used: 2.7692039012908936\n",
      "now process: citation_1912 current data count: 752 time used: 2.884356737136841\n",
      "now process: citation_1913 current data count: 783 time used: 2.9957070350646973\n",
      "now process: citation_1914 current data count: 804 time used: 3.3038816452026367\n",
      "now process: citation_1915 current data count: 830 time used: 3.565208673477173\n",
      "now process: citation_1916 current data count: 859 time used: 4.152202129364014\n",
      "now process: citation_1917 current data count: 921 time used: 4.49674129486084\n",
      "now process: citation_1918 current data count: 972 time used: 4.905072450637817\n",
      "now process: citation_1919 current data count: 1029 time used: 5.091635465621948\n",
      "now process: citation_1920 current data count: 1124 time used: 5.486839294433594\n",
      "now process: citation_1921 current data count: 1162 time used: 5.673694372177124\n",
      "now process: citation_1922 current data count: 1205 time used: 5.923142671585083\n",
      "now process: citation_1923 current data count: 1215 time used: 6.103030443191528\n",
      "now process: citation_1924 current data count: 1252 time used: 6.296697616577148\n",
      "now process: citation_1925 current data count: 2679 time used: 7.002426385879517\n",
      "now process: citation_1926 current data count: 7739 time used: 8.919304370880127\n",
      "now process: citation_1927 current data count: 13208 time used: 10.375602960586548\n",
      "now process: citation_1928 current data count: 18554 time used: 12.112201690673828\n",
      "now process: citation_1929 current data count: 23791 time used: 13.162056922912598\n",
      "now process: citation_1930 current data count: 29045 time used: 14.600144147872925\n",
      "now process: citation_1931 current data count: 35943 time used: 16.820455074310303\n",
      "now process: citation_1932 current data count: 43693 time used: 19.17488932609558\n",
      "now process: citation_1933 current data count: 51697 time used: 21.15238380432129\n",
      "now process: citation_1934 current data count: 59813 time used: 23.445528984069824\n",
      "now process: citation_1935 current data count: 68188 time used: 25.43506669998169\n",
      "now process: citation_1936 current data count: 76350 time used: 28.27897357940674\n",
      "now process: citation_1937 current data count: 82852 time used: 29.867937564849854\n",
      "now process: citation_1938 current data count: 90484 time used: 32.55139875411987\n",
      "now process: citation_1939 current data count: 98100 time used: 34.23315691947937\n",
      "now process: citation_1940 current data count: 104977 time used: 36.072176694869995\n",
      "now process: citation_1941 current data count: 112740 time used: 37.96071243286133\n",
      "now process: citation_1942 current data count: 119669 time used: 39.859944343566895\n",
      "now process: citation_1943 current data count: 126970 time used: 41.84390616416931\n",
      "now process: citation_1944 current data count: 133175 time used: 44.55843257904053\n",
      "now process: citation_1945 current data count: 138980 time used: 46.40586042404175\n",
      "now process: citation_1946 current data count: 144521 time used: 47.90276122093201\n",
      "now process: citation_1947 current data count: 149470 time used: 49.287681102752686\n",
      "now process: citation_1948 current data count: 154536 time used: 50.90199160575867\n",
      "now process: citation_1949 current data count: 159798 time used: 52.369194984436035\n",
      "now process: citation_1950 current data count: 165625 time used: 53.904232025146484\n",
      "now process: citation_1951 current data count: 171168 time used: 55.481226205825806\n",
      "now process: citation_1952 current data count: 177196 time used: 56.61348867416382\n",
      "now process: citation_1953 current data count: 183692 time used: 58.06386208534241\n",
      "now process: citation_1954 current data count: 190765 time used: 60.595006704330444\n",
      "now process: citation_1955 current data count: 198715 time used: 62.235965967178345\n",
      "now process: citation_1956 current data count: 207234 time used: 63.739463567733765\n",
      "now process: citation_1957 current data count: 207595 time used: 63.82783889770508\n",
      "now process: citation_1958 current data count: 216609 time used: 65.58697366714478\n",
      "now process: citation_1959 current data count: 226253 time used: 67.20929956436157\n",
      "now process: citation_1960 current data count: 235829 time used: 69.23841047286987\n",
      "now process: citation_1961 current data count: 246212 time used: 71.47730875015259\n",
      "now process: citation_1962 current data count: 256539 time used: 74.35928201675415\n",
      "now process: citation_1963 current data count: 268812 time used: 77.70571184158325\n",
      "now process: citation_1964 current data count: 281784 time used: 80.12767100334167\n",
      "now process: citation_1965 current data count: 294942 time used: 83.22188401222229\n",
      "now process: citation_1966 current data count: 308976 time used: 86.66853761672974\n",
      "now process: citation_1967 current data count: 324240 time used: 89.95066452026367\n",
      "now process: citation_1968 current data count: 341282 time used: 94.20380997657776\n",
      "now process: citation_1969 current data count: 358176 time used: 97.41920828819275\n",
      "now process: citation_1970 current data count: 378691 time used: 102.08222532272339\n",
      "now process: citation_1971 current data count: 402374 time used: 107.26784324645996\n",
      "now process: citation_1972 current data count: 428460 time used: 122.37531542778015\n",
      "now process: citation_1973 current data count: 454165 time used: 129.66098809242249\n",
      "now process: citation_1974 current data count: 479972 time used: 134.01371479034424\n",
      "now process: citation_1975 current data count: 508128 time used: 137.76986598968506\n",
      "now process: citation_1976 current data count: 539311 time used: 143.28699707984924\n",
      "now process: citation_1977 current data count: 571353 time used: 150.22635865211487\n",
      "now process: citation_1978 current data count: 602665 time used: 155.20946073532104\n",
      "now process: citation_1979 current data count: 640314 time used: 161.14188814163208\n",
      "now process: citation_1980 current data count: 678527 time used: 165.89920234680176\n",
      "now process: citation_1981 current data count: 724592 time used: 171.937153339386\n",
      "now process: citation_1982 current data count: 775550 time used: 179.94074201583862\n",
      "now process: citation_1983 current data count: 827453 time used: 190.87527871131897\n",
      "now process: citation_1984 current data count: 888633 time used: 200.29426431655884\n",
      "now process: citation_1985 current data count: 950610 time used: 208.13564491271973\n",
      "now process: citation_1986 current data count: 978631 time used: 210.55051970481873\n",
      "now process: citation_1987 current data count: 1046858 time used: 218.93226027488708\n",
      "now process: citation_1988 current data count: 1114991 time used: 226.13948583602905\n",
      "now process: citation_1989 current data count: 1185570 time used: 233.61026811599731\n",
      "now process: citation_1990 current data count: 1259830 time used: 242.60331082344055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now process: citation_1991 current data count: 1339270 time used: 251.6859905719757\n",
      "now process: citation_1992 current data count: 1414220 time used: 259.365531206131\n",
      "now process: citation_1993 current data count: 1496670 time used: 267.97916531562805\n",
      "now process: citation_1994 current data count: 1579884 time used: 275.5684063434601\n",
      "now process: citation_1995 current data count: 1667299 time used: 286.1555709838867\n",
      "now process: citation_1996 current data count: 1751136 time used: 293.7046115398407\n",
      "now process: citation_1997 current data count: 1834992 time used: 300.60383319854736\n",
      "now process: citation_1998 current data count: 1918420 time used: 306.9119622707367\n",
      "now process: citation_1999 current data count: 2003764 time used: 314.20783710479736\n",
      "now process: citation_2000 current data count: 2090495 time used: 321.1722490787506\n",
      "now process: citation_2001 current data count: 2179997 time used: 326.87858390808105\n",
      "now process: citation_2002 current data count: 2274894 time used: 333.6431586742401\n",
      "now process: citation_2003 current data count: 2367934 time used: 342.951189994812\n",
      "now process: citation_2004 current data count: 2467555 time used: 349.3302619457245\n",
      "now process: citation_2005 current data count: 2569837 time used: 356.6133062839508\n",
      "now process: citation_2006 current data count: 2617184 time used: 372.0668158531189\n",
      "now process: citation_2007 current data count: 2648518 time used: 376.05100536346436\n",
      "now process: citation_2008 current data count: 2676642 time used: 380.6366596221924\n",
      "now process: citation_2009 current data count: 2713079 time used: 386.5348823070526\n",
      "now process: citation_2010 current data count: 2750281 time used: 390.8844277858734\n",
      "now process: citation_2011 current data count: 2773325 time used: 395.2161543369293\n",
      "now process: citation_2012 current data count: 2793030 time used: 398.19840836524963\n",
      "now process: citation_2013 current data count: 2814602 time used: 418.9959006309509\n"
     ]
    }
   ],
   "source": [
    "# uncomment if you don't have preprocessed data\n",
    "# total data is around 450,000, of total size about 6GB\n",
    "#df_ready_to_csv = convert_to_binary_citation_data(citation_data_path, processed_data_path,verbose=1)\n",
    "#df_ready_to_csv.to_csv(os.path.join(processed_data_path,\"citation_data.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df_citation_data = pd.read_csv(processed_citation_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>year</th>\n",
       "      <th>judge_last_name</th>\n",
       "      <th>case_type</th>\n",
       "      <th>citation_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XFL742</td>\n",
       "      <td>1892</td>\n",
       "      <td>THAYER</td>\n",
       "      <td>contentMajOp</td>\n",
       "      <td>48 F. 62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XFLJLG</td>\n",
       "      <td>1892</td>\n",
       "      <td>THAYER</td>\n",
       "      <td>contentMajOp</td>\n",
       "      <td>16 F. 348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XFLJLG</td>\n",
       "      <td>1892</td>\n",
       "      <td>THAYER</td>\n",
       "      <td>contentMajOp</td>\n",
       "      <td>36 F. 668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XFL7H7</td>\n",
       "      <td>1892</td>\n",
       "      <td>MORROW</td>\n",
       "      <td>contentMajOp</td>\n",
       "      <td>49 F. 723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X9T9H7</td>\n",
       "      <td>1892</td>\n",
       "      <td>DEADY</td>\n",
       "      <td>contentMajOp</td>\n",
       "      <td>38 F. 789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  year judge_last_name     case_type citation_name\n",
       "0  XFL742  1892          THAYER  contentMajOp      48 F. 62\n",
       "1  XFLJLG  1892          THAYER  contentMajOp     16 F. 348\n",
       "2  XFLJLG  1892          THAYER  contentMajOp     36 F. 668\n",
       "3  XFL7H7  1892          MORROW  contentMajOp     49 F. 723\n",
       "4  X9T9H7  1892           DEADY  contentMajOp     38 F. 789"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>year</th>\n",
       "      <th>judge_last_name</th>\n",
       "      <th>case_type</th>\n",
       "      <th>citation_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XFL742</td>\n",
       "      <td>1892</td>\n",
       "      <td>THAYER</td>\n",
       "      <td>contentMajOp</td>\n",
       "      <td>48 F. 62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XFLJLG</td>\n",
       "      <td>1892</td>\n",
       "      <td>THAYER</td>\n",
       "      <td>contentMajOp</td>\n",
       "      <td>16 F. 348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XFLJLG</td>\n",
       "      <td>1892</td>\n",
       "      <td>THAYER</td>\n",
       "      <td>contentMajOp</td>\n",
       "      <td>36 F. 668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XFL7H7</td>\n",
       "      <td>1892</td>\n",
       "      <td>MORROW</td>\n",
       "      <td>contentMajOp</td>\n",
       "      <td>49 F. 723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X9T9H7</td>\n",
       "      <td>1892</td>\n",
       "      <td>DEADY</td>\n",
       "      <td>contentMajOp</td>\n",
       "      <td>38 F. 789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  year judge_last_name     case_type citation_name\n",
       "0  XFL742  1892          THAYER  contentMajOp      48 F. 62\n",
       "1  XFLJLG  1892          THAYER  contentMajOp     16 F. 348\n",
       "2  XFLJLG  1892          THAYER  contentMajOp     36 F. 668\n",
       "3  XFL7H7  1892          MORROW  contentMajOp     49 F. 723\n",
       "4  X9T9H7  1892           DEADY  contentMajOp     38 F. 789"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281593"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_id_list_unique = df_citation_data.caseid.unique()\n",
    "len(case_id_list_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350840"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_name_unique = df_citation_data.citation_name.unique()\n",
    "len(citation_name_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citation_data = df_citation_data[['caseid', 'citation_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_str = df_citation_data.to_csv('citation.edgelist', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id_to_index = dict( zip( case_id_list_unique, list(range(len(case_id_list_unique)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XEIVTFQNB5G0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_id_list_unique[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_id_to_index['XEIVTFQNB5G0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_name_to_index = dict( zip( citation_name_unique, list(range(len(citation_name_unique)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'48 F. 21'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_name_unique[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_name_to_index['48 F. 21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XFL742 48 F. 62\n",
      "0 0\n",
      "\n",
      "XFLJLG 16 F. 348\n",
      "1 1\n",
      "\n",
      "XFLJLG 36 F. 668\n",
      "1 2\n",
      "\n",
      "XFL7H7 49 F. 723\n",
      "2 3\n",
      "\n",
      "X9T9H7 38 F. 789\n",
      "3 4\n",
      "\n",
      "XEIVMJQNB5G0 48 F. 21\n",
      "4 5\n",
      "\n",
      "XEIVTFQNB5G0 51 F. 130\n",
      "5 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_citation_data.iterrows():\n",
    "    print(row['caseid'] + ' ' + row['citation_name'])\n",
    "    \n",
    "    line = str(case_id_to_index[row['caseid']]) + ' ' + str(citation_name_to_index[row['citation_name']]) + '\\n'\n",
    "    print(line)\n",
    "    if index > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "with open('citation.edgelist', 'w') as f:\n",
    "    for index, row in df_citation_data.iterrows():\n",
    "        line = str(case_id_to_index[row['caseid']]) + ' ' + str(citation_name_to_index[row['citation_name']]) + '\\n'\n",
    "        f.write(line)\n",
    "print(\"done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "with open('cases_citegraph.edgelist', 'w') as f:\n",
    "    for index, row in df_citation_data.iterrows():\n",
    "        line =  str(citation_name_to_index[row['citation_name']]) + ' ' + str(case_id_to_index[row['caseid']]) + '\\n'\n",
    "        f.write(line)\n",
    "print(\"done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('case_id_to_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(case_id_to_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id_to_index.pickle  citation.edgelist  citation_name_to_index.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data/Dropbox/judge_embedding_data_sp18/citation_graph_data_node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp case_id_to_index.pickle /data/Dropbox/judge_embedding_data_sp18/citation_graph_data_node2vec/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('case_id_to_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(citation_name_to_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('citation_name_to_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(citation_name_to_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing Node2Vec\n",
    "To produce node2vec, install node2vec package from: https://github.com/aditya-grover/node2vec .\n",
    "\n",
    "Run 'python node2vec_path/src/main.py --input cases_citegraph.edgelist --output citation_embeddings.emd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
